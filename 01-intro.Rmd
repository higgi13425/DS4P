# Introduction {#intro}

There are many books about Data Science. 
<br>
Why does the world need another one, particularly one targeting physicians?

- There is a lot of health care data
- There are a lot of interesting questions in health care
- There are particular and challenging issues in doing data analysis with PHI (Protected Health Information)

Syllabus:  Data Science for Physicians (DS4P)<br>

- Instructor: Peter Higgins, MD, PhD, MSc (CRDSA), Professor of Internal Medicine
- Office Hours: MSRB One 6510
- In-person class time
  - MSRB One 6510, Thursday evenings 6:30-8:30 PM
<br> 

## Course Description and Objectives

### Description
A practical introduction to data collection and security, data cleaning, statistical methods and computational tools needed to make sense of data, and methods for reporting and sharing your findings. This course is not a traditional introductory statistics courses in that computing plays a more central role than mathematics and a higher emphasis is placed on “thinking with data.” Topics include 

- secure HIPPA-compliant data collection
- data cleaning and validation
- data visualization
- data wrangling
- confidence intervals
- hypothesis testing, and 
- regression 
The course has no mathematics or computer science prerequisites.
<br>

### Objectives

1.	Have students engage in the data/science research pipeline in as faithful a manner as possible while maintaining a level suitable for novices.
2.	Foster a conceptual understanding of statistical topics and methods using real clinical data whenever possible, and simulation/resampling to support teaching concepts of inference. 
3.	Use a flipped classroom model by incorporating online learning for new concepts, with limited face-to-face time for real-time problem-solving 
4.	Introduce best practices for reproducible research and collaboration.
5.	Develop statistical literacy by, among other ways, tying in the curriculum to actual clinical data, demonstrating the importance statistics and computing plays in advancing medicine
<br>

### Topics
Roughly speaking we will cover the following topics (a more detailed outline is found below:

1.	Introduction and Tools (R, RStudio, and R Markdown)
2.	Data Import, and Handling
3.	Data Collection
4.	Checking, Validating, And Exploring your Data
5.	Data Types
6.	Data Wrangling with Tidyr and Dplyr
7.	Graphic Summaries for a Single Variable – ggplot package
8.	Descriptive Data for a Single Variable
9.	Graphic Summaries for Two or More Variables – ggplot2
10.	Descriptive Data for Two or More Variables
11.	Presenting your Results in a report with RMarkdown
12.	Statistical inference
13.	Study Design
14.	Sample Size and Power
15.	Sources of Bias
16.	Study Types
17.	One variable, single group
18.	One variable, two groups
19.	Multiple groups
20.	Linear Regression
21.	Reporting results interactively with Shiny
22.	Logistic Regression
23.	Meta-Analysis
<br>

### Learning Resources

•	E-Textbooks: 
Open Intro Statistics, at www.openintro.org  

•	E-Books on R
<br>
These are at different levels:

Level:    Absolute Beginner 
Textbook: R Basics	 
Goal:     Set up R and RStudio on a laptop, introduce the concept of an IDE  
Link:

Level:    New to R & Statistics	 
Textbook: Modern Dive 
Goal:     Learn basics of Data Management and visualization, introduction to hypothesis testing and statistical modeling   
Link:
<br>

Level:    Comfortable with R	
Textbook: Hands-On R Programming  
Goal:      
Link: 
<br>

Level:    Ready to Understand More	
Textbook: R for Data Science  
Link:      
<br>

•	Software: 

- Local laptop/desktop free open-source version of R and RStudio
- Cloud-based RStudio Server, which you can access in your browser via:
<br>
 Note if you are off-campus you must first log into the UM VPN. 
 
<br>
•	Online:

- DataCamp. A brower based interactive tool for learning R through short, focused courses, each 3-4 hours long.
- RStudio. Website with many resources for learning about the RStudio IDE and the tidyverse.
- r-cookbook – an often useful website with concrete examples of how to use R packages
- Stack Overflow and Google. Remarkably helpful to search for explanations of error messages, or explanations of problems that someone else has probably also experienced. For using Google, search for any topic or your error message and add “in R”
- package vignettes – variable quality, but when well done, can be extremely helpful examples of how to use the functions in each package
- R twitter – follow Rbloggers, #rstats
<br>

### Evaluation
This course is entirely voluntary. I hope that you will learn valuable skills that will advance your research career. I would like you to progress to using these skills on your own data as quickly as possible, as this will greatly help you reinforce your new skills. There are no grades and no formal evaluations. You can, however, earn certificates on DataCamp for completing courses.
<br>

### Task Goals
1.	Learn concepts through Data Camp  
a.	Multiple short courses to correspond with each unit
2.	Test yourself with assignments in ModernDive
a.	Chapters corresponding to each unit
3.	Three Challenges
a.	Clean data and perform descriptive data analysis on the biofire dataset
b.	Clean data and model outcomes in the health satisfaction dataset, producing a final report
c.	Use logistic regression to model dichotomous outcomes and produce a Shiny app to allow users to make predictions for future patients 
4.	Final Project 
There will be a final capstone project. This is an opportunity for you to use your statistics and data science skills developed during the challenges and perform your own start-to-finish data analysis project. The project will involving you addressing a scientific question by choosing a data set (or preferably, using one of your own), performing an analysis using the concepts and tools we have covered in this course, and writing a report. This can be done solo or with a partner.
<br>

### Learning Goals
1.	Recognize the importance of data collection, identify limitations in data collection methods, and determine how they affect the generalizability of your findings
2.	Use statistical software (R) to summarize data numerically and visually, and to perform data analysis.
3.	Have a conceptual understanding of statistical inference.
4.	Apply estimation and testing methods to analyze single variables or the relationship between two variables in order to understand data relationships and make data-based conclusions.
5.	Model numerical response variables and dichotomous response variables using a single explanatory variable or multiple explanatory variables in order to investigate relationships between variables.
6.	Interpret results correctly, effectively, and in context without relying on statistical jargon.
7.	Critique data-based claims and evaluate data-based decisions.
<br>

### Tips for success
1.	Read materials for each unit
2.	Do Data Camp courses for each unit – usually around 1 chapter (1 hour) per day.
3.	Do Data Camp daily practice on any day that you don’t have time to do a full chapter
4.	At end of each course, review material, take notes, copy/reproduce/save code on your laptop
5.	Try new skills on your own data, or on one of the open data sets
6.	Use RStudio and DataCamp Cheat sheets
7.	Annotate your code to help ‘future you’ understand it.
8.	Save and reuse your code for future projects
<br>

### Expected work load  
This course is entirely voluntary. It is expected that you have lots of clinical and/or research work to keep up with, along with the occasional call or night rotation. This is an investment in future skills to help your career. I recommend that you try to do up to one hour a day on most days, and on days when that is not realistic, to just do the 10 minutes of daily practice on DataCamp to keep the information fresh in your mind.  
<br>
Other learning resources:
<br>
<br>
<br>


You can label chapter and section titles using `{#label}` after them, e.g., we can reference Chapter \@ref(intro). If you do not manually label them, there will be automatic labels anyway, e.g., Chapter \@ref(methods).

Figures and tables with captions will be placed in `figure` and `table` environments, respectively.

```{r nice-fig, fig.cap='Here is a nice figure!', out.width='80%', fig.asp=.75, fig.align='center'}
par(mar = c(4, 4, .1, .1))
plot(pressure, type = 'b', pch = 19)
```

Reference a figure by its code chunk label with the `fig:` prefix, e.g., see Figure \@ref(fig:nice-fig). Similarly, you can reference tables generated from `knitr::kable()`, e.g., see Table \@ref(tab:nice-tab).

```{r nice-tab, tidy=FALSE}
knitr::kable(
  head(iris, 20), caption = 'Here is a nice table!',
  booktabs = TRUE
)
```

You can write citations, too. For example, we are using the **bookdown** package [@R-bookdown] in this sample book, which was built on top of R Markdown and **knitr** [@xie2015].
